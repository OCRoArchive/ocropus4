{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separated-bumper",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Full OCRopus 4 Training and Running\n",
    "\n",
    "This worksheet demonstrates OCRopus 4 training from start to finish, including bootstrapping using another OCR system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-cement",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Important Notes:\n",
    "\n",
    "- this does NOT yield usable models since the training data set used in this worksheet is so small and limited\n",
    "- this implements the main components of an OCR system and is suitable for text indexing and other applications, but full page recognition requires some additional components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pleased-factor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.system(\"sos convert full.ipynb full.sos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secure-madonna",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "display = 10\n",
    "multiplier = 1000\n",
    "maxextract = \n",
    "nwordtrain = 1000 * multiplier\n",
    "nsegtrain = 200 * multiplier\n",
    "nrottrain = 200 * multiplier\n",
    "nskewtrain = 200 * multiplier\n",
    "nscaletrain = 200 * multiplier\n",
    "nbintrain = 10 * multiplier\n",
    "dataurl = 'http://storage.googleapis.com/ocropus4/Volume_0000.tar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-tonight",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Download Dataset and Run Tesseract\n",
    "\n",
    "The dataset is Volume 0 from Google's 1000 Book dataset. These images are camera scanned, modest resolution, modest quality images. This volume contains a mix of English and Gaelic.\n",
    "\n",
    "_This dataset is used here for demonstration purposes only. It is not large or diverse enough to train a practical recognizer. You can obtain a usable recognizer by training on the UW3 dataset, but unfortunately that's not redistributable. We are currently putting together a larger, representative training set._\n",
    "\n",
    "We use Tesseract as our bootstrap OCR system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hairy-formation",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[download]\n",
    "input: []\n",
    "output: 'Volume_0000.tar'\n",
    "sh: expand=True\n",
    "    curl {dataurl} > Volume_0000.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "apparent-eagle",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_logging sos_info\">INFO: Running <span class=\"sos_highlight\">download</span>: \n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"sos_logging sos_info\">INFO: <span class=\"sos_highlight\">download</span> (index=0) is <span class=\"sos_highlight\">ignored</span> due to saved signature\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"sos_logging sos_info\">INFO: <span class=\"sos_highlight\">download</span> output:   <span class=\"sos_highlight\">Volume_0000.tar</span>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"sos_logging sos_info\">INFO: Workflow download (ID=wb0bbeca10f70367f) is ignored with 1 ignored step.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sosrun download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-variance",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Binarization\n",
    "\n",
    "By default, we binarize with a hardcoded binarizer based on grayscale morphology. This binarizer is purely CPU based (we may eventually port it to the GPU). It has worked very well in many different settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "casual-assets",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[binarize]\n",
    "input: 'Volume_0000.tar'\n",
    "output: 'raw.tar'\n",
    "sh: expand=True\n",
    "    vocropus nlbin binarize Volume_0000.tar --gray --output raw.tar --maxrec {maxextract}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opened-penalty",
   "metadata": {
    "kernel": "SoS",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_logging sos_info\">INFO: Running <span class=\"sos_highlight\">binarize</span>: \n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume_0000/pg0194\n",
      "Volume_0000/pg0439\n",
      "Volume_0000/pg0011\n",
      "Volume_0000/pg0205\n",
      "Volume_0000/pg0113\n",
      "Volume_0000/pg0018\n",
      "Volume_0000/pg0351\n",
      "Volume_0000/pg0021\n",
      "Volume_0000/pg0410\n",
      "Volume_0000/pg0079\n",
      "Volume_0000/pg0449\n",
      "Volume_0000/pg0214\n",
      "Volume_0000/pg0110\n",
      "Volume_0000/pg0080\n",
      "Volume_0000/pg0081\n",
      "Volume_0000/pg0058\n",
      "Volume_0000/pg0049\n",
      "Volume_0000/pg0067\n",
      "Volume_0000/pg0300\n",
      "Volume_0000/pg0510\n",
      "Volume_0000/pg0154\n",
      "Volume_0000/pg0501\n",
      "Volume_0000/pg0509\n",
      "Volume_0000/pg0084\n",
      "Volume_0000/pg0085\n",
      "Volume_0000/pg0224\n",
      "Volume_0000/pg0334\n",
      "Volume_0000/pg0421\n",
      "Volume_0000/pg0257\n",
      "Volume_0000/pg0135\n",
      "Volume_0000/pg0326\n",
      "Volume_0000/pg0148\n",
      "Volume_0000/pg0517\n",
      "Volume_0000/pg0298\n",
      "Volume_0000/pg0087\n",
      "Volume_0000/pg0307\n",
      "Volume_0000/pg0511\n",
      "Volume_0000/pg0043\n",
      "Volume_0000/pg0473\n",
      "Volume_0000/pg0366\n",
      "Volume_0000/pg0432\n",
      "Volume_0000/pg0103\n",
      "Volume_0000/pg0230\n",
      "Volume_0000/pg0138\n",
      "Volume_0000/pg0478\n",
      "Volume_0000/pg0361\n",
      "Volume_0000/pg0175\n",
      "Volume_0000/pg0415\n",
      "Volume_0000/pg0299\n",
      "Volume_0000/pg0006\n",
      "Volume_0000/pg0353\n",
      "Volume_0000/pg0166\n",
      "Volume_0000/pg0367\n",
      "Volume_0000/pg0068\n",
      "Volume_0000/pg0402\n",
      "Volume_0000/pg0233\n",
      "Volume_0000/pg0263\n",
      "Volume_0000/pg0319\n",
      "Volume_0000/pg0057\n",
      "Volume_0000/pg0386\n",
      "Volume_0000/pg0131\n",
      "Volume_0000/pg0112\n",
      "Volume_0000/pg0475\n",
      "Volume_0000/pg0063\n",
      "Volume_0000/pg0381\n",
      "Volume_0000/pg0123\n",
      "Volume_0000/pg0310\n",
      "Volume_0000/pg0266\n",
      "Volume_0000/pg0391\n",
      "Volume_0000/pg0464\n",
      "Volume_0000/pg0176\n",
      "Volume_0000/pg0327\n",
      "Volume_0000/pg0362\n",
      "Volume_0000/pg0206\n",
      "Volume_0000/pg0276\n",
      "Volume_0000/pg0083\n",
      "Volume_0000/pg0466\n",
      "Volume_0000/pg0340\n",
      "Volume_0000/pg0470\n",
      "Volume_0000/pg0383\n",
      "Volume_0000/pg0312\n",
      "Volume_0000/pg0178\n",
      "Volume_0000/pg0321\n",
      "Volume_0000/pg0270\n",
      "Volume_0000/pg0109\n",
      "Volume_0000/pg0001\n",
      "Volume_0000/pg0416\n",
      "Volume_0000/pg0268\n",
      "Volume_0000/pg0207\n",
      "Volume_0000/pg0457\n",
      "Volume_0000/pg0044\n",
      "Volume_0000/pg0462\n",
      "Volume_0000/pg0002\n",
      "Volume_0000/pg0097\n",
      "Volume_0000/pg0104\n",
      "Volume_0000/pg0167\n",
      "Volume_0000/pg0091\n",
      "Volume_0000/pg0029\n",
      "Volume_0000/pg0045\n",
      "Volume_0000/pg0237\n",
      "Volume_0000/pg0504\n",
      "Volume_0000/pg0406\n",
      "Volume_0000/pg0126\n",
      "Volume_0000/pg0229\n",
      "Volume_0000/pg0005\n",
      "Volume_0000/pg0143\n",
      "Volume_0000/pg0209\n",
      "Volume_0000/pg0269\n",
      "Volume_0000/pg0325\n",
      "Volume_0000/pg0461\n",
      "Volume_0000/pg0127\n",
      "Volume_0000/pg0142\n",
      "Volume_0000/pg0152\n",
      "Volume_0000/pg0296\n",
      "Volume_0000/pg0180\n",
      "Volume_0000/pg0040\n",
      "Volume_0000/pg0105\n",
      "Volume_0000/pg0064\n",
      "Volume_0000/pg0444\n",
      "Volume_0000/pg0164\n",
      "Volume_0000/pg0446\n",
      "Volume_0000/pg0261\n",
      "Volume_0000/pg0512\n",
      "Volume_0000/pg0198\n",
      "Volume_0000/pg0023\n",
      "Volume_0000/pg0435\n",
      "Volume_0000/pg0275\n",
      "Volume_0000/pg0343\n",
      "Volume_0000/pg0412\n",
      "Volume_0000/pg0000\n",
      "Volume_0000/pg0003\n",
      "Volume_0000/pg0265\n",
      "Volume_0000/pg0290\n",
      "Volume_0000/pg0089\n",
      "Volume_0000/pg0241\n",
      "Volume_0000/pg0338\n",
      "Volume_0000/pg0095\n",
      "Volume_0000/pg0248\n",
      "Volume_0000/pg0427\n",
      "Volume_0000/pg0286\n",
      "Volume_0000/pg0373\n",
      "Volume_0000/pg0443\n",
      "Volume_0000/pg0368\n",
      "Volume_0000/pg0158\n",
      "Volume_0000/pg0515\n",
      "Volume_0000/pg0215\n",
      "Volume_0000/pg0041\n",
      "Volume_0000/pg0431\n",
      "Volume_0000/pg0130\n",
      "Volume_0000/pg0035\n",
      "Volume_0000/pg0061\n",
      "Volume_0000/pg0202\n",
      "Volume_0000/pg0480\n",
      "Volume_0000/pg0129\n",
      "Volume_0000/pg0304\n",
      "Volume_0000/pg0372\n",
      "Volume_0000/pg0193\n",
      "Volume_0000/pg0358\n",
      "Volume_0000/pg0490\n",
      "Volume_0000/pg0347\n",
      "Volume_0000/pg0272\n",
      "Volume_0000/pg0168\n",
      "Volume_0000/pg0155\n",
      "Volume_0000/pg0260\n",
      "Volume_0000/pg0400\n",
      "Volume_0000/pg0289\n",
      "Volume_0000/pg0436\n",
      "Volume_0000/pg0420\n",
      "Volume_0000/pg0344\n",
      "Volume_0000/pg0468\n",
      "Volume_0000/pg0204\n",
      "Volume_0000/pg0500\n",
      "Volume_0000/pg0364\n",
      "Volume_0000/pg0141\n",
      "Volume_0000/pg0320\n",
      "Volume_0000/pg0055\n",
      "Volume_0000/pg0199\n",
      "Volume_0000/pg0380\n",
      "Volume_0000/pg0133\n",
      "Volume_0000/pg0455\n",
      "Volume_0000/pg0484\n",
      "Volume_0000/pg0424\n",
      "Volume_0000/pg0429\n",
      "Volume_0000/pg0258\n",
      "Volume_0000/pg0474\n",
      "Volume_0000/pg0075\n",
      "Volume_0000/pg0378\n",
      "Volume_0000/pg0422\n",
      "Volume_0000/pg0051\n",
      "Volume_0000/pg0354\n",
      "Volume_0000/pg0281\n",
      "Volume_0000/pg0454\n",
      "Volume_0000/pg0117\n",
      "Volume_0000/pg0009\n",
      "Volume_0000/pg0393\n",
      "Volume_0000/pg0407\n",
      "Volume_0000/pg0498\n",
      "Volume_0000/pg0423\n",
      "Volume_0000/pg0384\n",
      "Volume_0000/pg0174\n",
      "Volume_0000/pg0092\n",
      "Volume_0000/pg0417\n",
      "Volume_0000/pg0150\n",
      "Volume_0000/pg0324\n",
      "Volume_0000/pg0352\n",
      "Volume_0000/pg0028\n",
      "Volume_0000/pg0285\n",
      "Volume_0000/pg0121\n",
      "Volume_0000/pg0456\n",
      "Volume_0000/pg0186\n",
      "Volume_0000/pg0483\n",
      "Volume_0000/pg0163\n",
      "Volume_0000/pg0437\n",
      "Volume_0000/pg0295\n",
      "Volume_0000/pg0489\n",
      "Volume_0000/pg0497\n",
      "Volume_0000/pg0459\n",
      "Volume_0000/pg0190\n",
      "Volume_0000/pg0102\n",
      "Volume_0000/pg0017\n",
      "Volume_0000/pg0032\n",
      "Volume_0000/pg0350\n",
      "Volume_0000/pg0100\n",
      "Volume_0000/pg0503\n",
      "Volume_0000/pg0046\n",
      "Volume_0000/pg0197\n",
      "Volume_0000/pg0469\n",
      "Volume_0000/pg0430\n",
      "Volume_0000/pg0189\n",
      "Volume_0000/pg0486\n",
      "Volume_0000/pg0072\n",
      "Volume_0000/pg0428\n",
      "Volume_0000/pg0453\n",
      "Volume_0000/pg0050\n",
      "Volume_0000/pg0106\n",
      "Volume_0000/pg0471\n",
      "Volume_0000/pg0267\n",
      "Volume_0000/pg0238\n",
      "Volume_0000/pg0119\n",
      "Volume_0000/pg0330\n",
      "Volume_0000/pg0292\n",
      "Volume_0000/pg0037\n",
      "Volume_0000/pg0308\n",
      "Volume_0000/pg0357\n",
      "Volume_0000/pg0208\n",
      "Volume_0000/pg0302\n",
      "Volume_0000/pg0356\n",
      "Volume_0000/pg0136\n",
      "Volume_0000/pg0128\n",
      "Volume_0000/pg0071\n",
      "Volume_0000/pg0306\n",
      "Volume_0000/pg0273\n",
      "Volume_0000/pg0210\n",
      "Volume_0000/pg0048\n",
      "Volume_0000/pg0060\n",
      "Volume_0000/pg0203\n",
      "Volume_0000/pg0244\n",
      "Volume_0000/pg0516\n",
      "Volume_0000/pg0311\n",
      "Volume_0000/pg0460\n",
      "Volume_0000/pg0251\n",
      "Volume_0000/pg0232\n",
      "Volume_0000/pg0171\n",
      "Volume_0000/pg0022\n",
      "Volume_0000/pg0329\n",
      "Volume_0000/pg0020\n",
      "Volume_0000/pg0283\n",
      "Volume_0000/pg0508\n",
      "Volume_0000/pg0182\n",
      "Volume_0000/pg0337\n",
      "Volume_0000/pg0452\n",
      "Volume_0000/pg0476\n",
      "Volume_0000/pg0062\n",
      "Volume_0000/pg0404\n",
      "Volume_0000/pg0134\n",
      "Volume_0000/pg0370\n",
      "Volume_0000/pg0401\n",
      "Volume_0000/pg0375\n",
      "Volume_0000/pg0201\n",
      "Volume_0000/pg0228\n",
      "Volume_0000/pg0458\n",
      "Volume_0000/pg0179\n",
      "Volume_0000/pg0240\n",
      "Volume_0000/pg0488\n",
      "Volume_0000/pg0288\n",
      "Volume_0000/pg0008\n",
      "Volume_0000/pg0348\n",
      "Volume_0000/pg0397\n",
      "Volume_0000/pg0108\n",
      "Volume_0000/pg0426\n",
      "Volume_0000/pg0139\n",
      "Volume_0000/pg0053\n",
      "Volume_0000/pg0451\n",
      "Volume_0000/pg0414\n",
      "Volume_0000/pg0012\n",
      "Volume_0000/pg0217\n",
      "Volume_0000/pg0264\n",
      "Volume_0000/pg0004\n",
      "Volume_0000/pg0463\n",
      "Volume_0000/pg0016\n",
      "Volume_0000/pg0145\n",
      "Volume_0000/pg0331\n",
      "Volume_0000/pg0492\n",
      "Volume_0000/pg0070\n",
      "Volume_0000/pg0156\n",
      "Volume_0000/pg0250\n",
      "Volume_0000/pg0077\n",
      "Volume_0000/pg0235\n",
      "Volume_0000/pg0078\n",
      "Volume_0000/pg0253\n",
      "Volume_0000/pg0448\n",
      "Volume_0000/pg0196\n",
      "Volume_0000/pg0200\n",
      "Volume_0000/pg0274\n",
      "Volume_0000/pg0315\n",
      "Volume_0000/pg0293\n",
      "Volume_0000/pg0413\n",
      "Volume_0000/pg0211\n",
      "Volume_0000/pg0496\n",
      "Volume_0000/pg0074\n",
      "Volume_0000/pg0069\n",
      "Volume_0000/pg0116\n",
      "Volume_0000/pg0162\n",
      "Volume_0000/pg0185\n",
      "Volume_0000/pg0245\n",
      "Volume_0000/pg0389\n",
      "Volume_0000/pg0125\n",
      "Volume_0000/pg0442\n",
      "Volume_0000/pg0369\n",
      "Volume_0000/pg0322\n",
      "Volume_0000/pg0297\n",
      "Volume_0000/pg0096\n",
      "Volume_0000/pg0218\n",
      "Volume_0000/pg0172\n",
      "Volume_0000/pg0408\n",
      "Volume_0000/pg0395\n",
      "Volume_0000/pg0349\n",
      "Volume_0000/pg0120\n",
      "Volume_0000/pg0024\n",
      "Volume_0000/pg0169\n",
      "Volume_0000/pg0317\n",
      "Volume_0000/pg0505\n",
      "Volume_0000/pg0160\n",
      "Volume_0000/pg0499\n",
      "Volume_0000/pg0433\n",
      "Volume_0000/pg0323\n",
      "Volume_0000/pg0149\n",
      "Volume_0000/pg0495\n",
      "Volume_0000/pg0114\n",
      "Volume_0000/pg0284\n",
      "Volume_0000/pg0277\n",
      "Volume_0000/pg0399\n",
      "Volume_0000/pg0059\n",
      "Volume_0000/pg0409\n",
      "Volume_0000/pg0243\n",
      "Volume_0000/pg0212\n",
      "Volume_0000/pg0339\n",
      "Volume_0000/pg0382\n",
      "Volume_0000/pg0507\n",
      "Volume_0000/pg0385\n",
      "Volume_0000/pg0177\n",
      "Volume_0000/pg0195\n",
      "Volume_0000/pg0052\n",
      "Volume_0000/pg0279\n",
      "Volume_0000/pg0090\n",
      "Volume_0000/pg0333\n",
      "Volume_0000/pg0392\n",
      "Volume_0000/pg0479\n",
      "Volume_0000/pg0252\n",
      "Volume_0000/pg0054\n",
      "Volume_0000/pg0073\n",
      "Volume_0000/pg0309\n",
      "Volume_0000/pg0262\n",
      "Volume_0000/pg0394\n",
      "Volume_0000/pg0434\n",
      "Volume_0000/pg0111\n",
      "Volume_0000/pg0039\n",
      "Volume_0000/pg0472\n",
      "Volume_0000/pg0234\n",
      "Volume_0000/pg0335\n",
      "Volume_0000/pg0487\n",
      "Volume_0000/pg0305\n",
      "Volume_0000/pg0255\n",
      "Volume_0000/pg0187\n",
      "Volume_0000/pg0506\n",
      "Volume_0000/pg0405\n",
      "Volume_0000/pg0336\n",
      "Volume_0000/pg0015\n",
      "Volume_0000/pg0360\n",
      "Volume_0000/pg0247\n",
      "Volume_0000/pg0019\n",
      "Volume_0000/pg0341\n",
      "Volume_0000/pg0398\n",
      "Volume_0000/pg0030\n",
      "Volume_0000/pg0513\n",
      "Volume_0000/pg0036\n",
      "Volume_0000/pg0088\n",
      "Volume_0000/pg0485\n",
      "Volume_0000/pg0481\n",
      "Volume_0000/pg0031\n",
      "Volume_0000/pg0493\n",
      "Volume_0000/pg0065\n",
      "Volume_0000/pg0027\n",
      "Volume_0000/pg0494\n",
      "Volume_0000/pg0445\n",
      "Volume_0000/pg0226\n",
      "Volume_0000/pg0387\n",
      "Volume_0000/pg0007\n",
      "Volume_0000/pg0388\n",
      "Volume_0000/pg0482\n",
      "Volume_0000/pg0188\n",
      "Volume_0000/pg0280\n",
      "Volume_0000/pg0379\n",
      "Volume_0000/pg0066\n",
      "Volume_0000/pg0181\n",
      "Volume_0000/pg0419\n",
      "Volume_0000/pg0082\n",
      "Volume_0000/pg0191\n",
      "Volume_0000/pg0342\n",
      "Volume_0000/pg0256\n",
      "Volume_0000/pg0151\n",
      "Volume_0000/pg0146\n",
      "Volume_0000/pg0153\n",
      "Volume_0000/pg0355\n",
      "Volume_0000/pg0318\n",
      "Volume_0000/pg0345\n",
      "Volume_0000/pg0093\n",
      "Volume_0000/pg0042\n",
      "Volume_0000/pg0220\n",
      "Volume_0000/pg0242\n",
      "Volume_0000/pg0159\n",
      "Volume_0000/pg0411\n",
      "Volume_0000/pg0010\n",
      "Volume_0000/pg0365\n",
      "Volume_0000/pg0013\n",
      "Volume_0000/pg0223\n",
      "Volume_0000/pg0278\n",
      "Volume_0000/pg0140\n",
      "Volume_0000/pg0465\n",
      "Volume_0000/pg0165\n",
      "Volume_0000/pg0137\n",
      "Volume_0000/pg0213\n",
      "Volume_0000/pg0377\n",
      "Volume_0000/pg0173\n",
      "Volume_0000/pg0227\n",
      "Volume_0000/pg0225\n",
      "Volume_0000/pg0076\n",
      "Volume_0000/pg0231\n",
      "Volume_0000/pg0450\n",
      "Volume_0000/pg0107\n",
      "Volume_0000/pg0101\n",
      "Volume_0000/pg0291\n",
      "Volume_0000/pg0086\n",
      "Volume_0000/pg0390\n",
      "Volume_0000/pg0147\n",
      "Volume_0000/pg0259\n",
      "Volume_0000/pg0056\n",
      "Volume_0000/pg0363\n",
      "Volume_0000/pg0467\n",
      "Volume_0000/pg0183\n",
      "Volume_0000/pg0026\n",
      "Volume_0000/pg0144\n",
      "Volume_0000/pg0014\n",
      "Volume_0000/pg0502\n",
      "Volume_0000/pg0374\n",
      "Volume_0000/pg0514\n",
      "Volume_0000/pg0025\n",
      "Volume_0000/pg0301\n",
      "Volume_0000/pg0447\n",
      "Volume_0000/pg0115\n",
      "Volume_0000/pg0477\n",
      "Volume_0000/pg0440\n",
      "Volume_0000/pg0221\n",
      "Volume_0000/pg0170\n",
      "Volume_0000/pg0314\n",
      "Volume_0000/pg0038\n",
      "Volume_0000/pg0441\n",
      "Volume_0000/pg0236\n",
      "Volume_0000/pg0118\n",
      "Volume_0000/pg0161\n",
      "Volume_0000/pg0425\n",
      "Volume_0000/pg0254\n",
      "Volume_0000/pg0287\n",
      "Volume_0000/pg0098\n",
      "Volume_0000/pg0316\n",
      "Volume_0000/pg0282\n",
      "Volume_0000/pg0371\n",
      "Volume_0000/pg0184\n",
      "Volume_0000/pg0034\n",
      "Volume_0000/pg0033\n",
      "Volume_0000/pg0157\n",
      "Volume_0000/pg0418\n",
      "Volume_0000/pg0403\n",
      "Volume_0000/pg0249\n",
      "Volume_0000/pg0346\n",
      "Volume_0000/pg0122\n",
      "Volume_0000/pg0438\n",
      "Volume_0000/pg0239\n",
      "Volume_0000/pg0216\n",
      "Volume_0000/pg0491\n",
      "Volume_0000/pg0192\n",
      "Volume_0000/pg0099\n",
      "Volume_0000/pg0271\n",
      "Volume_0000/pg0294\n",
      "Volume_0000/pg0222\n",
      "Volume_0000/pg0124\n",
      "Volume_0000/pg0094\n",
      "Volume_0000/pg0047\n",
      "Volume_0000/pg0313\n",
      "Volume_0000/pg0376\n",
      "Volume_0000/pg0303\n",
      "Volume_0000/pg0396\n",
      "Volume_0000/pg0132\n",
      "Volume_0000/pg0246\n",
      "Volume_0000/pg0328\n",
      "Volume_0000/pg0359\n",
      "Volume_0000/pg0219\n",
      "Volume_0000/pg0332\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"sos_logging sos_info\">INFO: <span class=\"sos_highlight\">binarize</span> output:   <span class=\"sos_highlight\">raw.tar</span>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"sos_logging sos_info\">INFO: Workflow binarize (ID=w121f2cee93c4f828) is executed successfully with 1 completed step.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sosrun binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-objective",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Bootstrap OCR Recognizer\n",
    "\n",
    "We're using Tesseract as the bootstrap OCR engine. Tesseract runs on the normalized images returned in the previous step. The bootstrap OCR recognizer can have a moderately high error rate and OCRopus 4 can still be trained on it successfully. In fact, once you have trained an initial OCRopus 4 recognizer, you can use it as the bootstrap recognizer for additional source materials. OCRopus 4 is, in effect, self-training and self-improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-entry",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "!rebuild=y ./dtess --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-allergy",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[tess]\n",
    "input: 'raw.tar'\n",
    "output: 'tess.tar'\n",
    "sh: expand=True\n",
    "    rebuild=y dtess --help\n",
    "    tarp proc -c $(pwd)/'dtess sample.nrm.jpg sample.tess -l eng hocr; rm -f sample.lines.png sample.pseg.png' {_input} -o {_output}.tar.temp\n",
    "    mv {_output}.tar.temp {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-wedding",
   "metadata": {
    "kernel": "SoS",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sosrun tess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-shaft",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Generating Training Datasets\n",
    "\n",
    "OCRopus 4 training starts with tar files containing pairs of images and corresponding hOCR output. These are used to generate training data for word and line recognition and page segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-intake",
   "metadata": {
    "kernel": "Python3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-penalty",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "figsize(12, 8)\n",
    "import webdataset as wds\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-pharmaceutical",
   "metadata": {
    "kernel": "Python3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = wds.WebDataset(\"tess.tar\").decode(\"rgb8\")\n",
    "sample = next(islice(ds, 33, 999))\n",
    "print(sample.keys())\n",
    "print(sample[\"tess.hocr\"].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-birth",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "figsize(15, 10)\n",
    "imshow(sample[\"nrm.jpg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-matter",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Segmentation Data\n",
    "\n",
    "Segmentation algorithms are usually trained on four-label segmentation targets consisting of markers, areas, separators, and background. The `extract-seg hocr2seg` subcommand extracts those training images.\n",
    "\n",
    "Ordinarily, we would extract this data from many shards and shuffle it for training, but we're dispensing with that in this simple example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-christopher",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[seg-data]\n",
    "input: 'tess.tar'\n",
    "output: 'book-seg.tar'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    vocropus extract-seg hocr2seg {_input} --output {_output}.temp --element ocrx_word --extensions 'nrm.jpg tess.hocr' --invert True \\\n",
    "        --show 100 --labels='1, 2, 3' --check word --maxcount {maxextract}\n",
    "    mv {_output}.temp {_output}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-compensation",
   "metadata": {
    "kernel": "SoS",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sosrun seg-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-roman",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "ds = wds.WebDataset(\"book-seg.tar\").decode(\"rgb\")\n",
    "sample= next(islice(iter(ds), 500, 999))\n",
    "print(sample.keys())\n",
    "subplot(121); imshow(sample[\"png\"])\n",
    "subplot(122); imshow(sample[\"seg.png\"][...,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-brass",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Word Training Data\n",
    "\n",
    "As before, we use `extract-rec hocr2rec` to extract word training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-empire",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[word-data]\n",
    "input: 'tess.tar'\n",
    "output: 'book-words.tar'\n",
    "sh: expand=True\n",
    "    vocropus extract-rec hocr2rec {_input} --output {_output}.temp --element ocrx_word --extensions 'nrm.jpg tess.hocr' \\\n",
    "        --bounds 10,10,500,100 --dictionary /usr/share/dict/american-english-huge --maxcount {maxextract} \\\n",
    "        --acceptable-conf 60.0\n",
    "    mv {_output}.temp {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-baghdad",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%sosrun word-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-findings",
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "figsize(12, 8)\n",
    "import webdataset as wds\n",
    "from itertools import islice\n",
    "ds = wds.WebDataset(\"book-words.tar\").decode(\"rgb\")\n",
    "start = 55\n",
    "for i, sample in enumerate(islice(iter(ds), start, start+250, 10)):\n",
    "    subplot(5, 5, i+1)\n",
    "    imshow(sample[\"png\"])\n",
    "    title(sample[\"txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-geneva",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Detecting Character Outliers\n",
    "\n",
    "We need to decide on a character training set. Here is some optional code that goes through all training strings and identifies rare and unusual characters.\n",
    "\n",
    "You can use the output from this optional step either to transform the text strings in the training data, or to add new character set classes to OCRopus 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-fruit",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[detect-outliers]\n",
    "input: 'book-words.tar'\n",
    "output: 'bad-chars.txt'\n",
    "\n",
    "python:\n",
    "\n",
    "    ds = wds.WebDataset(\"book-words.tar\").decode(\"rgb\")\n",
    "    alltext = [sample[\"txt\"] for sample in ds]\n",
    "\n",
    "    from collections import Counter\n",
    "    counter = Counter()\n",
    "    for s in alltext: counter.update(s)\n",
    "\n",
    "    for c, n in counter.most_common():\n",
    "        if len(str(c.encode(\"unicode_escape\"))) > 4:\n",
    "            print(f\"\"\"{c} {str(c.encode(\"unicode_escape\")):10s} {n:10d}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-assist",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Training a Word Segmenter\n",
    "\n",
    "This is the training script for word segmentation. It's pretty straightforward and just uses the `book-seg.tar` data generated previously.\n",
    "\n",
    "All training jobs log to Sqlite3 databases and also save their models into those databases. You can use the `ocropus4 slog` subcommand to extract the best or the last model and plot training curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-perspective",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[train-segs]\n",
    "input: 'book-seg.tar'\n",
    "output: 'segtrain.pth'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    vocropus ocroseg train {_input} --log-to segtrain.sqlite3 --ntrain {nsegtrain} --display {display}\n",
    "    vocropus slog getlast segtrain.sqlite3 --output {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-astronomy",
   "metadata": {
    "kernel": "SoS",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sosrun train-segs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-struggle",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Training a Word Recognizer\n",
    "\n",
    "To train a word recognizer, we use the `ocroline train` command using the `book-words.tar` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-warrior",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[train-words]\n",
    "input: 'book-words.tar'\n",
    "output: 'wordtrain.pth'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    vocropus ocroline train {_input} --log-to wordtrain.sqlite3 --ntrain {nwordtrain} --display {display}\n",
    "    vocropus slog getlast wordtrain.sqlite3 --output {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-silver",
   "metadata": {
    "kernel": "SoS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%sosrun train-words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-progressive",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Line Segmentation\n",
    "\n",
    "The base recognizer recognizes individual words; these need to be grouped into text lines as part of the recognition process. We train a separate text line segmentation model for this. The procedure is the same as for word segmentation: we generate line segmentation images for training and then use the `ocroseg train` command to train a segmenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-sequence",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[line-data]\n",
    "input: 'tess.tar'\n",
    "output: 'book-lines.tar'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    vocropus extract-seg hocr2seg {_input} --output {_output}.temp --element ocr_line --extensions 'nrm.jpg tess.hocr' --invert True \\\n",
    "        --show 100 --labels='1, 2, 3' --check line --maxcount {maxextract}\n",
    "    mv {_output}.temp {_output}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-metro",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sosrun line-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-prime",
   "metadata": {
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = wds.WebDataset(\"book-lines.tar\").decode(\"rgb\")\n",
    "sample= next(islice(iter(ds), 100, 999))\n",
    "print(sample.keys())\n",
    "subplot(121); imshow(sample[\"png\"])\n",
    "subplot(122); imshow(sample[\"seg.png\"][...,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-funds",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[train-lines]\n",
    "input: 'book-lines.tar'\n",
    "output: 'linetrain.pth'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    vocropus ocroseg train {_input} --log-to linetrain.sqlite3 --ntrain {nsegtrain} --display {display}\n",
    "    vocropus slog getlast linetrain.sqlite3 --output {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-determination",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sosrun train-lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-disclosure",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Running the Page Recognizer\n",
    "\n",
    "The page reocgnizer consists of several steps:\n",
    "\n",
    "- word segmentation: segment the input page into individual words\n",
    "- word recognition: apply the word recognizer to the word segments\n",
    "- line segmentation: apply the line segmenter to obtain text line seeds\n",
    "- grouping: use the line segmentation output to group word boxes into text line\n",
    "- sorting: text lines are finally sorted in a simple way to obtain the final output\n",
    "\n",
    "Output is both in .tar format and as a single .html file in hOCR format (the hOCR is not compliant yet).\n",
    "\n",
    "The final sort currently uses simple heuristics; eventually, there will be a second grouping step based on text block training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-halloween",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[page-recognition]\n",
    "input: 'tess.tar'\n",
    "output: 'recognized.tar'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    vocropus pagerec recognize {_input} --output {_output} --recmodel wordtrain.pth --segmodel segtrain.pth --lgmodel linetrain.pth --full-html recognized.html --extensions nrm.jpg --maxrec 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-wings",
   "metadata": {
    "kernel": "SoS",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sosrun page-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-gabriel",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Here are some recognition results; these are NOT representative of what is achievable with OCRopus 4, since they are recognition results obtained on a tiny training data set with limited training data. Given this very limited training, recognition performance is actually pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-portable",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "!lynx -dump recognized.html | tail -30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-arrow",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Page Orientation\n",
    "\n",
    "Before any kind of document processing, it is a good idea to ensure that pages are right side up. The `ocrorot` command handles this. We can first train a page orientation model and then apply it to correct the orientation of pages. Training just requires a collection of pages in right-side-up orientation as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-football",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[train-rot]\n",
    "input: 'tess.tar'\n",
    "output: 'rottrain.pth'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    base=$(basename {_output} .pth)\n",
    "    rm -f $base.sqlite3\n",
    "    vocropus ocrorot train {_input} --display 15 --output $base.sqlite3 --nsamples {nrottrain} --replicate 8 --num-workers 8 --extensions nrm.jpg\n",
    "    vocropus slog getbest $base.sqlite3 --output {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-bacteria",
   "metadata": {
    "kernel": "SoS",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sosrun train-rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-injury",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[predict-rot]\n",
    "input: 'rottrain.pth'\n",
    "sh: expand=True\n",
    "    vocropus ocrorot correct tess.tar --nsamples 10 --model rottrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-tongue",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%sosrun predict-rot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-hebrew",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Page Skew Correction\n",
    "\n",
    "\"Page skew\" refers to small rotations of scanned pages--small deviations from the vertical. The `ocroskew` command can be used to train page skew models and perform page skew correction. These models are generally trained and applied after page orientation correction. Training just requires a collection of already deskewed images as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-evidence",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[train-skew]\n",
    "input: 'tess.tar'\n",
    "output: 'skewtrain.pth'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    base=$(basename {_output} .pth)\n",
    "    rm -f $base.sqlite3\n",
    "    vocropus ocroskew train {_input} --display 15 --output $base.sqlite3 --nsamples {nskewtrain} --replicate 8 --num-workers 8 --extensions 'nrm.jpg'\n",
    "    vocropus slog getbest $base.sqlite3 --output {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-parish",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%sosrun train-skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-machinery",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[predict-skew]\n",
    "input: 'skewtrain.pth'\n",
    "sh: expand=True\n",
    "    vocropus ocroskew correct tess.tar --nsamples 10 --model skewtrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-diving",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%sosrun predict-skew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-petite",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Page Scale Analysis\n",
    "\n",
    "Document layout analysis, and to a lesser degree text recognition, assumes that documents are presented at a fairly consistent image resolution (usually 300 dpi). The `ocroscale` command can be trained on a collection of documents at the desired target resolution (e.g., 300 dpi) and when applied to novel documents, will estimate the document scale relative to the training collection. No other ground truth is necessary.\n",
    "\n",
    "The `ocroscale` command has the option for page-by-page \"scale correction\", though for bulk processing, it is better to estimate the scale factor for a new batch of documents once and then rescale the entire document batch with a consistent scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-shadow",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[train-scale]\n",
    "input: 'tess.tar'\n",
    "output: 'scaletrain.pth'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    base=$(basename {_output} .pth)\n",
    "    rm -f $base.sqlite3\n",
    "    vocropus ocroscale train {_input} --display 15 --output $base.sqlite3 --nsamples {nscaletrain} --replicate 8 --num-workers 8\n",
    "    vocropus slog getbest $base.sqlite3 --output {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-diameter",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%sosrun train-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-retailer",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[predict-scale]\n",
    "input: 'scaletrain.pth'\n",
    "sh: expand=True\n",
    "    vocropus ocroscale hist tess.tar --nsamples 10 --model skewtrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-dryer",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%sosrun predict-scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-mambo",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Document Binarization Models\n",
    "\n",
    "For most documents, it is best to first convert them to binary format. Binarization models can be trained and applied with the `ocrobin` command.\n",
    "\n",
    "Here, we are training the binarization model on the output of the `nlbin` command. While this may seem redundant, the `ocrobin` output is actually slightly better, and more importantly, the `ocrobin` binarizer runs on the GPU and is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-monday",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[train-bin]\n",
    "input: 'raw.tar'\n",
    "output: 'bintrain.pth'\n",
    "sh: expand=True\n",
    "    export MPLBACKEND=TkAgg\n",
    "    base=$(basename {_output} .pth)\n",
    "    rm -f $base.sqlite3\n",
    "    vocropus ocrobin train {_input} --display 15 --output $base.sqlite3 --nsamples {nbintrain} --extensions 'jpg nrm.jpg' --lr 1e-3 --replicate 8 --num-workers 8\n",
    "    vocropus slog getbest $base.sqlite3 --output {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-throat",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%sosrun train-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-carry",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFD91A",
     {
      "name": "ipython",
      "version": 3
     }
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
